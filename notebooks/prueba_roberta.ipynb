{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### PRUEBA CON 30 TWEETS DE LA API, PARA PROBAR EL ENTRENAMIENTO DEL MODELO CON POCOS DATOS.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "from transformers import RobertaTokenizer\n",
    "import toml\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.utils import resample\n",
    "from sklearn.model_selection import train_test_split\n",
    "from transformers import RobertaTokenizer\n",
    "import torch\n",
    "from transformers import RobertaForSequenceClassification, AdamW\n",
    "from torch.utils.data import DataLoader\n",
    "import time\n",
    "from sklearn.metrics import accuracy_score\n",
    "from deep_translator import GoogleTranslator\n",
    "import torch.nn as nn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "translator = Translator()\n",
    "pd.options.display.max_columns = 20\n",
    "pd.options.display.max_rows = 20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>tweets</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Sat Oct 05 15:00:34 +0000 2024</td>\n",
       "      <td>Now you can see the streaming of Premodern Mad...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Sat Oct 05 15:00:34 +0000 2024</td>\n",
       "      <td>@FedeeValver Madrid will concede</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Thu Sep 19 01:00:00 +0000 2024</td>\n",
       "      <td>Celebrate Prof. Oscar Garcia-Prada's 60th birt...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Sat Oct 05 15:00:31 +0000 2024</td>\n",
       "      <td>@Steve_Labile Frero arretez de lui trouver une...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Sat Oct 05 15:00:30 +0000 2024</td>\n",
       "      <td>‚öΩÔ∏èüí• Back Inter Milan, Real Madrid and Sporting...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Sat Oct 05 15:00:29 +0000 2024</td>\n",
       "      <td>@Alvaro_varito Florentino cada vez pasa m√°s fr...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Sat Oct 05 15:00:28 +0000 2024</td>\n",
       "      <td>@GxlDeMessi18 Penal para el real de Madrid</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Tue Oct 01 13:01:57 +0000 2024</td>\n",
       "      <td>Unlock your best self with fasting! üçΩÔ∏èüí™ Burn f...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Sat Oct 05 15:00:24 +0000 2024</td>\n",
       "      <td>@madrid_total2 Como me encanta que sin estar e...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Sat Oct 05 15:00:22 +0000 2024</td>\n",
       "      <td>Hoy nos pita el √°rbitro del Frente Atl√©tico. h...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Sat Oct 05 15:00:22 +0000 2024</td>\n",
       "      <td>EL PROXIMO JUEVES A LAS 17 HORAS ESTARA CON NO...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>Sat Oct 05 15:00:22 +0000 2024</td>\n",
       "      <td>üìä La Liga 2024/25 Standings! üèÜ\\n\\n1. FC Barcel...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>Mon Sep 30 11:05:54 +0000 2024</td>\n",
       "      <td>Aloita treenit kympill√§! 1.-13.10.2024 liittym...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>Sat Oct 05 15:00:21 +0000 2024</td>\n",
       "      <td>@Recort131 Zizou lo arreglaba eh, o eso o se i...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>Sat Oct 05 15:00:19 +0000 2024</td>\n",
       "      <td>üá™üá∏¬†La Liga Match Day¬†üî•\\n‚öΩ¬†Villareal VS Real Ma...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>Sat Oct 05 15:00:19 +0000 2024</td>\n",
       "      <td>@madrid_total2 Mi casaü§ç\\n\\nüìçMazatlan, Mexico</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>Sat Oct 05 15:00:17 +0000 2024</td>\n",
       "      <td>@CCivicaCatalana Que se venga a Madrid. Dumpin...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>Sat Oct 05 15:00:14 +0000 2024</td>\n",
       "      <td>@garroyo25 @Angel_gaitan_of @navedelmisterio A...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>Sat Oct 05 15:00:14 +0000 2024</td>\n",
       "      <td>@Jomuvaz @LukitaMD @Brunex_02 Inf√≥rmese un poc...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>Sat Oct 05 15:00:12 +0000 2024</td>\n",
       "      <td>@GxlDeMessi18 Penalti para el Real Madrid en e...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>Sat Oct 05 15:00:12 +0000 2024</td>\n",
       "      <td>@abajofirmante75 @SrNaninho @Ramon_AlvarezMM P...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>Sat Oct 05 15:00:10 +0000 2024</td>\n",
       "      <td>@Tex_Jonathan Gara‚Äù Arnol bre\\nOtak dia udah d...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>Sat Oct 05 15:00:09 +0000 2024</td>\n",
       "      <td>@IDGoonerscom ya bener sih Arsenal ga bakal ju...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                 0  \\\n",
       "0   Sat Oct 05 15:00:34 +0000 2024   \n",
       "1   Sat Oct 05 15:00:34 +0000 2024   \n",
       "2   Thu Sep 19 01:00:00 +0000 2024   \n",
       "3   Sat Oct 05 15:00:31 +0000 2024   \n",
       "4   Sat Oct 05 15:00:30 +0000 2024   \n",
       "5   Sat Oct 05 15:00:29 +0000 2024   \n",
       "6   Sat Oct 05 15:00:28 +0000 2024   \n",
       "7   Tue Oct 01 13:01:57 +0000 2024   \n",
       "8   Sat Oct 05 15:00:24 +0000 2024   \n",
       "9   Sat Oct 05 15:00:22 +0000 2024   \n",
       "10  Sat Oct 05 15:00:22 +0000 2024   \n",
       "11  Sat Oct 05 15:00:22 +0000 2024   \n",
       "12  Mon Sep 30 11:05:54 +0000 2024   \n",
       "13  Sat Oct 05 15:00:21 +0000 2024   \n",
       "14  Sat Oct 05 15:00:19 +0000 2024   \n",
       "15  Sat Oct 05 15:00:19 +0000 2024   \n",
       "16  Sat Oct 05 15:00:17 +0000 2024   \n",
       "17  Sat Oct 05 15:00:14 +0000 2024   \n",
       "18  Sat Oct 05 15:00:14 +0000 2024   \n",
       "19  Sat Oct 05 15:00:12 +0000 2024   \n",
       "20  Sat Oct 05 15:00:12 +0000 2024   \n",
       "21  Sat Oct 05 15:00:10 +0000 2024   \n",
       "22  Sat Oct 05 15:00:09 +0000 2024   \n",
       "\n",
       "                                               tweets  \n",
       "0   Now you can see the streaming of Premodern Mad...  \n",
       "1                    @FedeeValver Madrid will concede  \n",
       "2   Celebrate Prof. Oscar Garcia-Prada's 60th birt...  \n",
       "3   @Steve_Labile Frero arretez de lui trouver une...  \n",
       "4   ‚öΩÔ∏èüí• Back Inter Milan, Real Madrid and Sporting...  \n",
       "5   @Alvaro_varito Florentino cada vez pasa m√°s fr...  \n",
       "6          @GxlDeMessi18 Penal para el real de Madrid  \n",
       "7   Unlock your best self with fasting! üçΩÔ∏èüí™ Burn f...  \n",
       "8   @madrid_total2 Como me encanta que sin estar e...  \n",
       "9   Hoy nos pita el √°rbitro del Frente Atl√©tico. h...  \n",
       "10  EL PROXIMO JUEVES A LAS 17 HORAS ESTARA CON NO...  \n",
       "11  üìä La Liga 2024/25 Standings! üèÜ\\n\\n1. FC Barcel...  \n",
       "12  Aloita treenit kympill√§! 1.-13.10.2024 liittym...  \n",
       "13  @Recort131 Zizou lo arreglaba eh, o eso o se i...  \n",
       "14  üá™üá∏¬†La Liga Match Day¬†üî•\\n‚öΩ¬†Villareal VS Real Ma...  \n",
       "15       @madrid_total2 Mi casaü§ç\\n\\nüìçMazatlan, Mexico  \n",
       "16  @CCivicaCatalana Que se venga a Madrid. Dumpin...  \n",
       "17  @garroyo25 @Angel_gaitan_of @navedelmisterio A...  \n",
       "18  @Jomuvaz @LukitaMD @Brunex_02 Inf√≥rmese un poc...  \n",
       "19  @GxlDeMessi18 Penalti para el Real Madrid en e...  \n",
       "20  @abajofirmante75 @SrNaninho @Ramon_AlvarezMM P...  \n",
       "21  @Tex_Jonathan Gara‚Äù Arnol bre\\nOtak dia udah d...  \n",
       "22  @IDGoonerscom ya bener sih Arsenal ga bakal ju...  "
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#df_prueba_roberta = pd.read_csv('C:/Users/Agust√≠n/Desktop/4Geeks/Clases/30. Proyecto Final/Public Environment/Final-Project---Luis-Augustin-Ale/notebooks/aux_prueba.csv')\n",
    "#df_prueba_roberta = df_prueba_roberta.drop(columns=['Unnamed: 0'])\n",
    "df_prueba_roberta.rename(columns={'sentiment': 'tweets'}, inplace=True)\n",
    "df_prueba_roberta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>tweets</th>\n",
       "      <th>tweets_traducidos</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Sat Oct 05 15:00:34 +0000 2024</td>\n",
       "      <td>Now you can see the streaming of Premodern Mad...</td>\n",
       "      <td>Now you can see the streaming of Premodern Mad...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Sat Oct 05 15:00:34 +0000 2024</td>\n",
       "      <td>@FedeeValver Madrid will concede</td>\n",
       "      <td>@FedeeValver Madrid will concede</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Thu Sep 19 01:00:00 +0000 2024</td>\n",
       "      <td>Celebrate Prof. Oscar Garcia-Prada's 60th birt...</td>\n",
       "      <td>Celebrate Prof. Oscar Garcia-Prada's 60th birt...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Sat Oct 05 15:00:31 +0000 2024</td>\n",
       "      <td>@Steve_Labile Frero arretez de lui trouver une...</td>\n",
       "      <td>@Steve_Labile Brother stop making excuses for ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Sat Oct 05 15:00:30 +0000 2024</td>\n",
       "      <td>‚öΩÔ∏èüí• Back Inter Milan, Real Madrid and Sporting...</td>\n",
       "      <td>‚öΩÔ∏èüí• Back Inter Milan, Real Madrid and Sporting...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                0  \\\n",
       "0  Sat Oct 05 15:00:34 +0000 2024   \n",
       "1  Sat Oct 05 15:00:34 +0000 2024   \n",
       "2  Thu Sep 19 01:00:00 +0000 2024   \n",
       "3  Sat Oct 05 15:00:31 +0000 2024   \n",
       "4  Sat Oct 05 15:00:30 +0000 2024   \n",
       "\n",
       "                                              tweets  \\\n",
       "0  Now you can see the streaming of Premodern Mad...   \n",
       "1                   @FedeeValver Madrid will concede   \n",
       "2  Celebrate Prof. Oscar Garcia-Prada's 60th birt...   \n",
       "3  @Steve_Labile Frero arretez de lui trouver une...   \n",
       "4  ‚öΩÔ∏èüí• Back Inter Milan, Real Madrid and Sporting...   \n",
       "\n",
       "                                   tweets_traducidos  \n",
       "0  Now you can see the streaming of Premodern Mad...  \n",
       "1                   @FedeeValver Madrid will concede  \n",
       "2  Celebrate Prof. Oscar Garcia-Prada's 60th birt...  \n",
       "3  @Steve_Labile Brother stop making excuses for ...  \n",
       "4  ‚öΩÔ∏èüí• Back Inter Milan, Real Madrid and Sporting...  "
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''def traducir(text):\n",
    "    # Detectar el idioma autom√°ticamente y traducirlo al ingl√©s\n",
    "    if GoogleTranslator(source='auto', target='en').translate(text):\n",
    "        return GoogleTranslator(source='auto', target='en').translate(text)\n",
    "    else:\n",
    "        return text\n",
    "\n",
    "df_prueba_roberta['tweets_traducidos'] = df_prueba_roberta['tweets'].apply(traducir)'''\n",
    "df_prueba_roberta.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Agust√≠n\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\transformers\\tokenization_utils_base.py:1617: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be deprecated in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "tokenizer = RobertaTokenizer.from_pretrained('roberta-base')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "list"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tweets = df_prueba_roberta['tweets_traducidos'].to_list()\n",
    "type(tweets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoded_tweet = tokenizer.encode_plus(tweets, add_special_tokens=True,                      # Adds [CLS] and [SEP] \n",
    "                                      max_length=128,                                       # Max sequence length \n",
    "                                      padding='max_length',                                 # Pad to max_length \n",
    "                                      truncation=True,                                      # Truncate if the text is too long \n",
    "                                      return_attention_mask=True,                           # Return attention mask \n",
    "                                      return_tensors='pt')                                  # Return PyTorch tensors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3,\n",
      "         2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1]])\n",
      "tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0]])\n"
     ]
    }
   ],
   "source": [
    "print(encoded_tweet['input_ids'])\n",
    "print(encoded_tweet['attention_mask'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "58e1935567d14e8481a3eabe252efa1e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/499M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Agust√≠n\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\huggingface_hub\\file_download.py:147: UserWarning: `huggingface_hub` cache-system uses symlinks by default to efficiently store duplicated files but your machine does not support them in C:\\Users\\Agust√≠n\\.cache\\huggingface\\hub\\models--roberta-base. Caching files will still work but in a degraded version that might require more space on your disk. This warning can be disabled by setting the `HF_HUB_DISABLE_SYMLINKS_WARNING` environment variable. For more details, see https://huggingface.co/docs/huggingface_hub/how-to-cache#limitations.\n",
      "To support symlinks on Windows, you either need to activate Developer Mode or to run Python as an administrator. In order to activate developer mode, see this article: https://docs.microsoft.com/en-us/windows/apps/get-started/enable-your-device-for-development\n",
      "  warnings.warn(message)\n",
      "Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at roberta-base and are newly initialized: ['classifier.dense.bias', 'classifier.dense.weight', 'classifier.out_proj.bias', 'classifier.out_proj.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "model = RobertaForSequenceClassification.from_pretrained('roberta-base', num_labels=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### We freeze all layers and then unfreeze the last 2 layers. After we declare that layers from 12th forward will be trained"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for layer in model.roberta.encoder.layer[:10]:\n",
    "    for param in layer.parameters():\n",
    "        param.requires_grad = False\n",
    "\n",
    "# Unfreeze the last 2 layers\n",
    "for layer in model.roberta.encoder.layer[10:12]:\n",
    "    for param in layer.parameters():\n",
    "        param.requires_grad = True\n",
    "\n",
    "# Ensure layers after the 12th are trainable\n",
    "for layer in model.roberta.encoder.layer[12:]:\n",
    "    for param in layer.parameters():\n",
    "        param.requires_grad = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at roberta-base and are newly initialized: ['classifier.dense.bias', 'classifier.dense.weight', 'classifier.out_proj.bias', 'classifier.out_proj.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "### TRADUCIRRRRRRRRRRRRRRRRRRRRRRRRRRRRR\n",
    "\n",
    "# We declare a new class to load the ROBERTA model and add two personalized layers\n",
    "class CustomRobertaModel(nn.Module):\n",
    "    def __init__(self, num_labels=2):\n",
    "        super(CustomRobertaModel, self).__init__()\n",
    "        # We load the pretrained Roberta model base \n",
    "        self.roberta = RobertaForSequenceClassification.from_pretrained('roberta-base', num_labels=num_labels)\n",
    "        \n",
    "        # Agregamos capas adicionales densas (fully connected) \n",
    "        self.additional_layer_1 = nn.Linear(self.roberta.config.hidden_size, 512)                   # Capa adicional 1 - Realiza una transformacion lineal de la entrada \n",
    "        self.additional_layer_2 = nn.Linear(512, 256)                                               # Capa adicional 2\n",
    "        self.classifier = nn.Linear(256, num_labels)                                                # Capa final de clasificaci√≥n (ajusta el tama√±o seg√∫n tu tarea)\n",
    "        \n",
    "        # Funci√≥n de activaci√≥n\n",
    "        self.relu = nn.ReLU()\n",
    "    \n",
    "    def forward(self, input_ids, attention_mask=None, labels=None):\n",
    "        # Pasamos los datos a trav√©s del modelo de RoBERTa\n",
    "        outputs = self.roberta.roberta(input_ids=input_ids, attention_mask=attention_mask)\n",
    "        \n",
    "        # Obtenemos el embedding final (√∫ltima capa oculta de RoBERTa)\n",
    "        pooled_output = outputs[1]  # La salida de RoBERTa es una tupla: [0] son las logits, [1] el embedding\n",
    "        \n",
    "        # Pasamos por las capas adicionales\n",
    "        x = self.relu(self.additional_layer_1(pooled_output))\n",
    "        x = self.relu(self.additional_layer_2(x))\n",
    "        \n",
    "        # Capa final de clasificaci√≥n\n",
    "        logits = self.classifier(x)\n",
    "        \n",
    "        # Si se proporcionan etiquetas, calculamos la p√©rdida\n",
    "        if labels is not None:\n",
    "            loss_fn = nn.CrossEntropyLoss()\n",
    "            loss = loss_fn(logits, labels)\n",
    "            return loss, logits\n",
    "        else:\n",
    "            return torch.sigmoid(x)                         # previo code de esta linea era : return logits\n",
    "\n",
    "# Cargar el modelo personalizado\n",
    "model_custom = CustomRobertaModel(num_labels=2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Move the model to GPU (if available)\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "model_custom.to(device)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# COMO DICE CHATGPT QUE DEBERIA SEGUIR LA CODIFICACION, ADAPTAR\n",
    "'''\n",
    "# Asegurar que todos los par√°metros sean entrenables\n",
    "for param in model.parameters():\n",
    "    param.requires_grad = True\n",
    "\n",
    "# Definir optimizador\n",
    "optimizer = AdamW(model.parameters(), lr=2e-5)  # Ajusta el lr si es necesario\n",
    "\n",
    "# Configurar el entrenamiento\n",
    "epochs = 3\n",
    "model.train()  # Asegurar que el modelo est√° en modo entrenamiento\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    running_loss = 0.0\n",
    "    for batch in train_loader:\n",
    "        # Mover los datos al dispositivo\n",
    "        input_ids = batch['input_ids'].to(device)\n",
    "        attention_mask = batch['attention_mask'].to(device)\n",
    "        labels = batch['labels'].to(device)\n",
    "\n",
    "        # Reiniciar gradientes\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # Forward pass\n",
    "        outputs = model(input_ids, attention_mask=attention_mask, labels=labels)\n",
    "        loss = outputs.loss\n",
    "\n",
    "        # Backward pass y optimizaci√≥n\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        running_loss += loss.item()\n",
    "\n",
    "    print(f\"Epoch {epoch+1} Loss: {running_loss/len(train_loader)}\")\n",
    "'''"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
