{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from transformers import AutoModelForSequenceClassification, AutoTokenizer, RobertaForSequenceClassification, RobertaTokenizer\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "import sys\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "utils_path = r'C:\\Users\\aless\\Desktop\\final project 2.1\\Final-Project---Luis-Augustin-Ale\\utils'\n",
    "sys.path.append(os.path.abspath(utils_path))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from custom_class_final_model import CustomRobertaModel\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at roberta-base and are newly initialized: ['classifier.dense.bias', 'classifier.dense.weight', 'classifier.out_proj.bias', 'classifier.out_proj.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "# Load the pre-trained model and tokenizer from Hugging Face\n",
    "model_name = \"AleOfDurin/final_retrained_model\"\n",
    "# Load the model and tokenizer from the Hugging Face Hub\n",
    "model_custom = CustomRobertaModel.from_pretrained(model_name)\n",
    "tokenizer = RobertaTokenizer.from_pretrained(model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to predict the sentiment of a test phrase\n",
    "def predict_sentiment(model, tokenizer, sentence):\n",
    "    # Tokenize the input sentence\n",
    "    inputs = tokenizer(sentence, return_tensors=\"pt\", padding=True, truncation=True)\n",
    "    input_ids = inputs[\"input_ids\"]\n",
    "    attention_mask = inputs[\"attention_mask\"]\n",
    "\n",
    "    # Set model to evaluation mode\n",
    "    model.eval()\n",
    "    \n",
    "    # No gradient calculation for inference\n",
    "    with torch.no_grad():\n",
    "        outputs = model(input_ids=input_ids, attention_mask=attention_mask)\n",
    "        logits = outputs  # For custom model, it's just the logits\n",
    "    \n",
    "    # Get the predicted class (0 or 1)\n",
    "    predictions = torch.argmax(logits, dim=1)\n",
    "    return predictions.item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted Sentiment: Positive\n"
     ]
    }
   ],
   "source": [
    "test_sentence = \"TODAY HAS BEEN AWESOME. Now to lie in bed with laptop and galaxy\"  ### IMPUT HERE! \n",
    "predicted_label = predict_sentiment(model_custom, tokenizer, test_sentence)\n",
    "\n",
    "label_mapping = {0: \"Negative\", 1: \"Positive\"}  # Adjust based on your task\n",
    "print(f\"Predicted Sentiment: {label_mapping[predicted_label]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "' #### SOME SAMPLES FOR TESTING: ####839984,839984,is drinkin\\' tea &amp; watchin\\' tv ,1.0\\n2064541,2064541,awwww i m sure it will come my stomach s just growling for food gt,0.0\\n1540903,1540903,@REALTOR_VICKIE just keeping you on your toes! ,1.0\\n1729002,1729002,ugh i have to work til tonight but then i get to leave early sometime this week which will be friday the day before my week vaca,0.0\\n1597499,1597499,TODAY HAS BEEN AWESOME. Now to lie in bed with laptop and galaxy ,1.0\\n1610996,1610996,cleaning the house making barbie s bed as everyday and my face is burning,0.0\\n694541,694541,@DymeDiva23 Slave n @ work....was up n ready now get n tired n hungry   enjoy.,0.0\\n1432277,1432277,@AntixOnline  Yup! Sure did! It will be insane there.PLUS I really wanted to see my good bud Digital Dave who flew in from Pittsburgh!!  ,1.0\\n794675,794675,my computer hasn\\'t been working.  ( &lt;---haha belly rolls.,0.0\\n2582215,2582215,sounds like a good day ahead looking forward to meeting u,1.0\\n1786476,1786476,i want to go to the yfc thing tomorrow,0.0\\n2357465,2357465,still no word from the sw hoping michael s get to visit soon and home for good soon after,0.0\\n1533995,1533995,@andreamccorkle I guess I won\\'t send you any of those for reference on my business logo. ,1.0\\n70092,70092,\"Ah! Finally found a solution to the probably I\\'ve had on the i-Comm site! For reference: I wouldn\\'t recommend KickApps as a CMS, period. \",0.0\\n864509,864509,@Epiphora oh noo!! I\\'m sorry to hear that! (also - I got your super exciting scandalous gifties!!!! I can\\'t wait to try them!!) ,1.0\\n2995937,2995937,i think i have to eat something first so my sweet dreams have to wait,1.0\\n618682,618682,my phone\\'s pissing me off ,0.0\\n1999536,1999536,bummer i m so sorry to hear that,0.0\\n473260,473260,Just jumped out of my own skin when a takeaway menu or some Christian propaganda or similar popped through the letterbox. Unstable today ,0.0\\n2635373,2635373,yea its all worth it for some good bbq lol now im hungry lol,1.0\\n1697156,1697156,played some skifree this morning managed to escape the snow monster but a second one came to eat me fb,0.0\\n185390,185390,i\\'m sorry denver  drivin right past yal too,0.0\\n2751687,2751687,watching mtv movie awards who else is,1.0\\n1147232,1147232,Having a post-party drink or two at Blue 32 Sports Grill. What an amazingly fun night this has been  - http://bkite.com/081wZ,1.0\\n2697045,2697045,it has a great beat,1.0\\n552993,552993,@maliboobarbiee all the time. Mah friends got good taste. And they boo thangs be tryin to give me sum too. What\\'s a nigga to do  lol,0.0\\n455109,455109,Monday is coming ,0.0\\n1513992,1513992,@kNugroho knp te2hqu? ,1.0\\n154464,154464,booo stuck in town- two buses home ,0.0\\n1775208,1775208,the new curve twitterberry is wack,0.0'"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#samples for testing (choosen randomly)\n",
    "''' \n",
    "\n",
    "\n",
    "839984,839984,is drinkin' tea &amp; watchin' tv ,1.0\n",
    "2064541,2064541,awwww i m sure it will come my stomach s just growling for food gt,0.0\n",
    "1540903,1540903,@REALTOR_VICKIE just keeping you on your toes! ,1.0\n",
    "1729002,1729002,ugh i have to work til tonight but then i get to leave early sometime this week which will be friday the day before my week vaca,0.0\n",
    "1597499,1597499,TODAY HAS BEEN AWESOME. Now to lie in bed with laptop and galaxy ,1.0\n",
    "1610996,1610996,cleaning the house making barbie s bed as everyday and my face is burning,0.0\n",
    "694541,694541,@DymeDiva23 Slave n @ work....was up n ready now get n tired n hungry   enjoy.,0.0\n",
    "1432277,1432277,@AntixOnline  Yup! Sure did! It will be insane there.PLUS I really wanted to see my good bud Digital Dave who flew in from Pittsburgh!!  ,1.0\n",
    "794675,794675,my computer hasn't been working.  ( &lt;---haha belly rolls.,0.0\n",
    "2582215,2582215,sounds like a good day ahead looking forward to meeting u,1.0\n",
    "1786476,1786476,i want to go to the yfc thing tomorrow,0.0\n",
    "2357465,2357465,still no word from the sw hoping michael s get to visit soon and home for good soon after,0.0\n",
    "1533995,1533995,@andreamccorkle I guess I won't send you any of those for reference on my business logo. ,1.0\n",
    "70092,70092,\"Ah! Finally found a solution to the probably I've had on the i-Comm site! For reference: I wouldn't recommend KickApps as a CMS, period. \",0.0\n",
    "864509,864509,@Epiphora oh noo!! I'm sorry to hear that! (also - I got your super exciting scandalous gifties!!!! I can't wait to try them!!) ,1.0\n",
    "2995937,2995937,i think i have to eat something first so my sweet dreams have to wait,1.0\n",
    "618682,618682,my phone's pissing me off ,0.0\n",
    "1999536,1999536,bummer i m so sorry to hear that,0.0\n",
    "473260,473260,Just jumped out of my own skin when a takeaway menu or some Christian propaganda or similar popped through the letterbox. Unstable today ,0.0\n",
    "2635373,2635373,yea its all worth it for some good bbq lol now im hungry lol,1.0\n",
    "1697156,1697156,played some skifree this morning managed to escape the snow monster but a second one came to eat me fb,0.0\n",
    "185390,185390,i'm sorry denver  drivin right past yal too,0.0\n",
    "2751687,2751687,watching mtv movie awards who else is,1.0\n",
    "1147232,1147232,Having a post-party drink or two at Blue 32 Sports Grill. What an amazingly fun night this has been  - http://bkite.com/081wZ,1.0\n",
    "2697045,2697045,it has a great beat,1.0\n",
    "552993,552993,@maliboobarbiee all the time. Mah friends got good taste. And they boo thangs be tryin to give me sum too. What's a nigga to do  lol,0.0\n",
    "455109,455109,Monday is coming ,0.0\n",
    "1513992,1513992,@kNugroho knp te2hqu? ,1.0\n",
    "154464,154464,booo stuck in town- two buses home ,0.0\n",
    "1775208,1775208,the new curve twitterberry is wack,0.0\n",
    "\n",
    "'''"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
