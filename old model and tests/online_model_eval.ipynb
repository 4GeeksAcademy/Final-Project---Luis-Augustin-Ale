{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## EVALUATE MODEL is not working atm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "due to possible issues with the model uploaded on hugging faces the metrics are not good. the main problem is that the output of labels and predictions is:\n",
    "Predictions (all_preds): [0, 0, 0, 0, 0]\n",
    "Labels (all_labels): [0, 0, 0, 0, 0]\n",
    "\n",
    "while with the model saved locally we have:\n",
    "Predictions (all_preds): [0, 1, 1, 1, 1]\n",
    "Labels (all_labels): [0, 0, 1, 1, 1]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hugging Face Transformers and PyTorch\n",
    "import torch\n",
    "from transformers import AutoModelForSequenceClassification, AutoTokenizer, RobertaForSequenceClassification, RobertaTokenizer\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "\n",
    "\n",
    "# Sklearn for Model Evaluation\n",
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix, roc_auc_score\n",
    "import numpy as np\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "18cf83f17bae4d4d8b0b0ee6607374b8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/830 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "576b8ce6bbdd409baca8dba119a90489",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/496M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at AleOfDurin/full_model2.0 were not used when initializing RobertaForSequenceClassification: ['classifier.1.bias', 'classifier.1.weight']\n",
      "- This IS expected if you are initializing RobertaForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing RobertaForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at AleOfDurin/full_model2.0 and are newly initialized: ['classifier.dense.bias', 'classifier.dense.weight', 'classifier.out_proj.bias', 'classifier.out_proj.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "36ca1908ab494a0f8e231c20155befe4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/1.25k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8a587d59c5154d60982f6e9e01789711",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "vocab.json:   0%|          | 0.00/1.05M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d8a2f8bdf042487ab1e0af0c2a1c5820",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "merges.txt:   0%|          | 0.00/506k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cea7c36f29ac402ba8ad278ffded10be",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "special_tokens_map.json:   0%|          | 0.00/1.01k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Load the pre-trained model and tokenizer from Hugging Face\n",
    "model_name = \"AleOfDurin/full_model2.0\"\n",
    "# Load the model and tokenizer from the Hugging Face Hub\n",
    "model = RobertaForSequenceClassification.from_pretrained(model_name) # Ensure it's SequenceClassification model  --- ,num_labels=2) deleted as it was added to the json file\n",
    "tokenizer = RobertaTokenizer.from_pretrained(model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\aless\\AppData\\Local\\Temp\\ipykernel_188676\\861193737.py:2: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  val_encodings, val_labels = torch.load(r'C:\\Users\\aless\\Desktop\\final project 2.1\\val_encodings.pt')\n"
     ]
    }
   ],
   "source": [
    "# Load the tokenized validation dataset (save the file to the path desired and link it here)\n",
    "val_encodings, val_labels = torch.load(r'C:\\Users\\aless\\Desktop\\final project 2.1\\val_encodings.pt')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Move model to GPU for faster processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model and data moved to GPU, DataLoader set.\n"
     ]
    }
   ],
   "source": [
    "# Define the device: Check if GPU is available\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "# Move the model to the GPU\n",
    "model.to(device)\n",
    "\n",
    "# Set batch size and number of workers\n",
    "batch_size = 512\n",
    "num_workers = 8\n",
    "\n",
    "# Create the validation DataLoader with batch size 512 and workers set to 8\n",
    "val_dataset = TensorDataset(\n",
    "    val_encodings['input_ids'].to(device),  # Move input IDs to GPU\n",
    "    val_encodings['attention_mask'].to(device),  # Move attention masks to GPU\n",
    "    val_labels.to(device)  # Move labels to GPU\n",
    ")\n",
    "val_loader = DataLoader(val_dataset, batch_size=batch_size, num_workers=num_workers)\n",
    "\n",
    "# Set the model to evaluation mode\n",
    "model.eval()\n",
    "\n",
    "print(\"Model and data moved to GPU, DataLoader set.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.classifier = torch.nn.Sequential(\n",
    "    torch.nn.Dropout(0.3),  # Dropout as per the trained model\n",
    "    torch.nn.Linear(model.config.hidden_size, 2)  # Linear layer for binary classification\n",
    ").to(device) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tokenized Input IDs: tensor([[    0, 12861,  7728,  2788,   259,     2],\n",
      "        [    0, 21518,  7728,  2788,     2,     1]], device='cuda:0')\n",
      "Tokenized Attention Mask: tensor([[1, 1, 1, 1, 1, 1],\n",
      "        [1, 1, 1, 1, 1, 0]], device='cuda:0')\n"
     ]
    }
   ],
   "source": [
    "# Example: Re-tokenizing the validation dataset (assuming you have the raw text data)\n",
    "texts = [\"Your sample text here\", \"Another sample text\"]  # Replace with your dataset's text\n",
    "\n",
    "# Tokenize the texts\n",
    "tokenized_inputs = tokenizer(texts, padding=True, truncation=True, max_length=128, return_tensors=\"pt\")\n",
    "\n",
    "# Move tokenized inputs to the device\n",
    "input_ids = tokenized_inputs['input_ids'].to(device)\n",
    "attention_mask = tokenized_inputs['attention_mask'].to(device)\n",
    "\n",
    "# Debug: Print tokenized inputs\n",
    "print(f\"Tokenized Input IDs: {input_ids}\")\n",
    "print(f\"Tokenized Attention Mask: {attention_mask}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total inference time: 3127.95 seconds\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "\n",
    "# Start timer for inference\n",
    "start_time = time.time()\n",
    "\n",
    "# Initialize lists to store predictions and true labels\n",
    "all_preds = []\n",
    "all_labels = []\n",
    "y_proba = []  # Store probabilities for ROC-AUC\n",
    "\n",
    "# Set model to no_grad mode for inference\n",
    "with torch.no_grad():\n",
    "    # Loop through validation DataLoader\n",
    "    for step, batch in enumerate(val_loader):\n",
    "        # Move batch to the device (GPU or CPU)\n",
    "        input_ids, attention_mask, labels = [x.to(device) for x in batch]\n",
    "\n",
    "        # Check for NaN values in the input data\n",
    "        if torch.isnan(input_ids).any() or torch.isnan(attention_mask).any():\n",
    "            print(\"Input contains NaN values.\")\n",
    "            break  # Stop if NaNs are found\n",
    "        \n",
    "        # Remove mixed precision and run in full precision\n",
    "        outputs = model(input_ids=input_ids, attention_mask=attention_mask)\n",
    "        logits = outputs.logits\n",
    "        \n",
    "        # Use only the logits for the [CLS] token (first token) for classification\n",
    "        cls_logits = logits[:, 0, :]  # Extract the [CLS] token logits for each sequence\n",
    "        \n",
    "        # Predicted classes from [CLS] token\n",
    "        predictions = torch.argmax(cls_logits, dim=-1)\n",
    "        \n",
    "        # Probabilities for ROC-AUC from [CLS] token\n",
    "        probabilities = torch.softmax(cls_logits, dim=-1)[:, 1]  # Probabilities for class 1\n",
    "\n",
    "        # Store predictions and true labels\n",
    "        all_preds.extend(predictions.cpu().numpy())  # Store binary predictions for each sequence\n",
    "        all_labels.extend(labels.cpu().numpy())  # Store actual labels\n",
    "        y_proba.extend(probabilities.cpu().numpy())  # Store probabilities for ROC-AUC\n",
    "\n",
    "# Total time taken for inference\n",
    "total_time = time.time() - start_time\n",
    "print(f\"Total inference time: {total_time:.2f} seconds\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predictions (all_preds): [0, 0, 0, 0, 0]\n",
      "Labels (all_labels): [0, 0, 0, 0, 0]\n"
     ]
    }
   ],
   "source": [
    "# Check the shape and some example values\n",
    "print(f\"Predictions (all_preds): {all_preds[:5]}\")  # Print first 5 predictions\n",
    "print(f\"Labels (all_labels): {all_labels[:5]}\")  # Print first 5 labels\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted Class Distribution: {0: 119090, 1: 350633}\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Check distribution of predictions (if the model is predicting only one class)\n",
    "unique_preds, counts_preds = np.unique(all_preds, return_counts=True)\n",
    "pred_class_distribution = dict(zip(unique_preds, counts_preds))\n",
    "print(f\"Predicted Class Distribution: {pred_class_distribution}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'all_preds' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[3], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m all_preds_flat \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mconcatenate([pred\u001b[38;5;241m.\u001b[39mflatten() \u001b[38;5;28;01mfor\u001b[39;00m pred \u001b[38;5;129;01min\u001b[39;00m \u001b[43mall_preds\u001b[49m])\n\u001b[0;32m      2\u001b[0m all_labels_flat \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mconcatenate([label\u001b[38;5;241m.\u001b[39mflatten() \u001b[38;5;28;01mfor\u001b[39;00m label \u001b[38;5;129;01min\u001b[39;00m all_labels])\n\u001b[0;32m      3\u001b[0m y_proba_flat \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39marray(y_proba)\u001b[38;5;241m.\u001b[39mflatten()\n",
      "\u001b[1;31mNameError\u001b[0m: name 'all_preds' is not defined"
     ]
    }
   ],
   "source": [
    "all_preds_flat = np.concatenate([pred.flatten() for pred in all_preds])\n",
    "all_labels_flat = np.concatenate([label.flatten() for label in all_labels])\n",
    "y_proba_flat = np.array(y_proba).flatten()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.5983\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.71      0.35      0.47    239290\n",
      "           1       0.56      0.85      0.68    230433\n",
      "\n",
      "    accuracy                           0.60    469723\n",
      "   macro avg       0.64      0.60      0.57    469723\n",
      "weighted avg       0.64      0.60      0.57    469723\n",
      "\n",
      "Confusion Matrix:\n",
      "[[ 84855 154435]\n",
      " [ 34235 196198]]\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'y_proba_flat' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[49], line 15\u001b[0m\n\u001b[0;32m     12\u001b[0m \u001b[38;5;28mprint\u001b[39m(conf_matrix)\n\u001b[0;32m     14\u001b[0m \u001b[38;5;66;03m# ROC-AUC Score\u001b[39;00m\n\u001b[1;32m---> 15\u001b[0m roc_auc \u001b[38;5;241m=\u001b[39m roc_auc_score(all_labels_flat, \u001b[43my_proba_flat\u001b[49m)\n\u001b[0;32m     16\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mROC-AUC Score: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mroc_auc\u001b[38;5;132;01m:\u001b[39;00m\u001b[38;5;124m.4f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'y_proba_flat' is not defined"
     ]
    }
   ],
   "source": [
    "# Calculate Accuracy\n",
    "accuracy = accuracy_score(all_labels_flat, all_preds_flat)\n",
    "print(f\"Accuracy: {accuracy:.4f}\")\n",
    "\n",
    "# Generate Classification Report (Precision, Recall, F1-Score)\n",
    "report = classification_report(all_labels_flat, all_preds_flat)\n",
    "print(report)\n",
    "\n",
    "# Confusion Matrix\n",
    "conf_matrix = confusion_matrix(all_labels_flat, all_preds_flat)\n",
    "print(\"Confusion Matrix:\")\n",
    "print(conf_matrix)\n",
    "\n",
    "# ROC-AUC Score\n",
    "roc_auc = roc_auc_score(all_labels_flat, y_proba_flat)\n",
    "print(f\"ROC-AUC Score: {roc_auc:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "upload to hugging via code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The token has not been saved to the git credentials helper. Pass `add_to_git_credential=True` in this function directly or `--add-to-git-credential` if using via `huggingface-cli` if you want to set the git credential as well.\n",
      "Token is valid (permission: fineGrained).\n",
      "Your token has been saved to C:\\Users\\aless\\.cache\\huggingface\\token\n",
      "Login successful\n"
     ]
    }
   ],
   "source": [
    "from huggingface_hub import login\n",
    "\n",
    "login(token=\"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\")  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Attempting to upload config.json from C:\\Users\\aless\\Desktop\\final project 2.1\\full_model\\config.json...\n",
      "Successfully uploaded config.json to AleOfDurin/full_model2.0.\n",
      "Attempting to upload model.safetensors from C:\\Users\\aless\\Desktop\\final project 2.1\\full_model\\model.safetensors...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "61a284d79be34e0f843ba867f4a4400b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/496M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully uploaded model.safetensors to AleOfDurin/full_model2.0.\n",
      "Attempting to upload vocab.json from C:\\Users\\aless\\Desktop\\final project 2.1\\full_model\\vocab.json...\n",
      "Successfully uploaded vocab.json to AleOfDurin/full_model2.0.\n",
      "Attempting to upload tokenizer_config.json from C:\\Users\\aless\\Desktop\\final project 2.1\\full_model\\tokenizer_config.json...\n",
      "Successfully uploaded tokenizer_config.json to AleOfDurin/full_model2.0.\n",
      "Attempting to upload merges.txt from C:\\Users\\aless\\Desktop\\final project 2.1\\full_model\\merges.txt...\n",
      "Successfully uploaded merges.txt to AleOfDurin/full_model2.0.\n",
      "Attempting to upload special_tokens_map.json from C:\\Users\\aless\\Desktop\\final project 2.1\\full_model\\special_tokens_map.json...\n",
      "Successfully uploaded special_tokens_map.json to AleOfDurin/full_model2.0.\n",
      "All files processed.\n"
     ]
    }
   ],
   "source": [
    "from huggingface_hub import HfApi, upload_file\n",
    "import os\n",
    "\n",
    "# Define your Hugging Face repository name and the path to your local model directory\n",
    "repo_id = \"AleOfDurin/full_model2.0\"\n",
    "model_dir = r'C:\\Users\\aless\\Desktop\\final project 2.1\\full_model'\n",
    "token = \"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\"  # Replace this with your Hugging Face token\n",
    "\n",
    "# Initialize the HfApi object\n",
    "api = HfApi()\n",
    "\n",
    "# List of files to upload\n",
    "files_to_upload = [\"config.json\", \"model.safetensors\", \"vocab.json\", \"tokenizer_config.json\", \"merges.txt\", \"special_tokens_map.json\"]\n",
    "\n",
    "# Upload each file and provide debug information\n",
    "for file_name in files_to_upload:\n",
    "    try:\n",
    "        local_path = os.path.join(model_dir, file_name)\n",
    "        print(f\"Attempting to upload {file_name} from {local_path}...\")\n",
    "        \n",
    "        # Upload the file using the huggingface_hub\n",
    "        upload_file(\n",
    "            path_or_fileobj=local_path,\n",
    "            path_in_repo=file_name,\n",
    "            repo_id=repo_id,\n",
    "            token=token\n",
    "        )\n",
    "        \n",
    "        print(f\"Successfully uploaded {file_name} to {repo_id}.\")\n",
    "    \n",
    "    except Exception as e:\n",
    "        print(f\"Failed to upload {file_name}. Error: {e}\")\n",
    "        continue  # Move to the next file even if there's an error\n",
    "\n",
    "print(\"All files processed.\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
